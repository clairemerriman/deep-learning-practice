{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Theory\n",
    "\n",
    "Since my [academic research](https://scholar.google.com/citations?user=PDlwn_MAAAAJ&hl=en&oi=sra) in [ergodic theory](https://en.wikipedia.org/wiki/Ergodic_theory) and [symbolic dynamics](https://en.wikipedia.org/wiki/Symbolic_dynamics) uses Kolmogorov-Sinai entropy, based on Shannon entroy, I actually started with [Information Theory](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html). I have also added some more notes from [Shannon's original paper](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf) and other theoretical background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of encoding information, we are focused on bits of information ($0$ or $1$), so we use $\\log_2,$ but the same definition works using other bases. In particular, natural log is more common in theoretical mathematical work.\n",
    "\n",
    "If $x_i$ is an _event_ encoded with $n$ bits of information, and the probability of $x_i$ occuring is $p_i,$ then the  \n",
    "_self-information_ or _information content_ of $x_i$ is $$I(x_i)=-\\log_2 p_i=\\log_2 \\tfrac{1}{p_i}.$$ The self-information is also described as the _surprise_ at the event occuring. Note that $$\\lim_{p\\to 0^+}\\log_2 \\tfrac{1}{p}= \\infty \\quad \\textnormal{and}\\quad \\lim_{p\\to 1}\\log_2 \\tfrac{1}{p}=0,$$ which cooresponds to infinite surprise when an even with probability $0$ occurs and no surprise when an event with probability $1$ occurs.\n",
    "\n",
    "The _entropy_ of a system is expected value of the information of an event, given by $$H(X)=-\\sum_i p_i\\log_2 p_i.$$ If $x$ is instead a continuous variable in a space $X$, $$H(X)=-\\int_X p(x)\\log_2 p(x)dx.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "\n",
    "def nansum(x):\n",
    "    # Define nansum, as pytorch does not offer it inbuilt.\n",
    "    return x[~torch.isnan(x)].sum()\n",
    "\n",
    "def self_information(p):\n",
    "    return -torch.log2(torch.tensor(p)).item()\n",
    "\n",
    "self_information(1 / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6855)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(p):\n",
    "    entropy = - p * torch.log2(p)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(entropy)\n",
    "    return out\n",
    "\n",
    "entropy(torch.tensor([0.1, 0.5, 0.1, 0.3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ergodic theory assides\n",
    "For an event $x_i$ encoded with $n$ bits, $x_i \\in X=\\{0,1\\}^n.$ Since Shannon discusses the ergodic properties (includiing defining entropy!) of the corresponding Markov system, there is some map $T: X\\to X$ and the measure is $p(x).$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercises](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

These notes and exercises correspond to [Appendix: Mathematics for Deep Learning](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/index.html) from [Dive into Deep Learning](https://d2l.ai/index.html).

Since my [academic research](https://scholar.google.com/citations?user=PDlwn_MAAAAJ&hl=en&oi=sra) in [ergodic theory](https://en.wikipedia.org/wiki/Ergodic_theory) and [symbolic dynamics](https://en.wikipedia.org/wiki/Symbolic_dynamics) also uses Shannon entropy, I actually started with [Information Theory](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/information-theory.html). I have also added some more notes from [Shannon's original paper](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf) and other theoretical background. I may add some other problems related to my research.